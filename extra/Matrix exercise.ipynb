{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thinking in tensors, writing in PyTorch\n",
    "\n",
    "Hands-on training  by [Piotr Migda≈Ç](https://p.migdal.pl) (2019-2022).\n",
    "\n",
    "\n",
    "## Extra: matrix factorization\n",
    "\n",
    "See:\n",
    "\n",
    "* [Matrix decomposition viz](http://p.migdal.pl/matrix-decomposition-viz/) for some inspiration.\n",
    "* Section 4 from [From Customer Segmentation to Recommendation Systems](https://www.aitrends.com/machine-learning/ai-customer-targeting-levels/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "cities = [\"Toronto\", \"Warsaw\", \"Boston\", \"London\", \"San Francisco\", \"Jerusalem\", \"Mexico\", \"Cape Town\", \"Sydney\"]\n",
    "avg_temp = np.array([\n",
    "    [-5.8, -3.1, 4.5, 6.7, 14.3, 18.2, 20.1, 20.6, 15.9, 11.2, 3.6, -7.2],\n",
    "    [-2.9, 3.6, 4.2, 9.7, 16.1, 19.5, 20.0, 18.8, 16.4, 7.6, 3.2, 1.3],\n",
    "    [0.3, 1.5, 5.9, 8.4, 14.8, 20.2, 24.5, 24.7, 19.7, 13.0, 7.9, 1.9],\n",
    "    [2.3, 6.5, 8.7, 9.2, 12.3, 15.4, 17.3, 20.0, 14.8, 10.8, 8.7, 6.4],\n",
    "    [11.5, 13.9, 14.3, 15.7, 16.3, 17.4, 17.2, 17.7, 18.2, 17.4, 14.6, 10.4],\n",
    "    [9.7, 10.3, 12.7, 15.5, 21.2, 22.1, 24.1, 25.3, 23.5, 20.1, 15.7, 11.8],\n",
    "    [14.0, 15.6, 17.5, 20.3, 20.6, 18.1, 17.6, 18.2, 17.8, 16.8, 14.9, 16.0],\n",
    "    [23.1, 23.3, 21.4, 19.0, 17.1, 15.5, 15.4, 15.6, 15.4, 18.6, 20.9, 21.3],\n",
    "    [23.8, 24.6, 23.4, 20.8, 18.1, 15.1, 14.4, 14.5, 17.3, 19.0, 21.8, 24.3]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(avg_temp, index=cities, columns=months)\n",
    "sns.heatmap(df, annot=True, fmt='.0f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Using PyTorch, perform a matrix decomposition, i.e. $M = A B$.\n",
    "\n",
    "Hints:\n",
    "\n",
    "* NumPy to PyTorch: `torch.from_numpy(x)`\n",
    "* PyTorch to NumPy: `x.numpy()` or `x.detach().numpy()`\n",
    "* make sure or floats are `float32` (for Torch tensors use: `x = x.float()`)\n",
    "* view results and the training curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_temp_tensor = torch.from_numpy(avg_temp).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_loss(losses, logy=False):\n",
    "    print(\"Minimal loss: {:.3f}\".format(losses[-1]))\n",
    "    if logy:\n",
    "        plt.semilogy(range(len(losses)), losses)\n",
    "    else:\n",
    "        plt.plot(range(len(losses)), losses);\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load hint_matrix_1.py\n",
    "class Factorize(nn.Module):\n",
    "    \n",
    "    def __init__(self, factors=2):\n",
    "        super().__init__()\n",
    "        self.A = Parameter(torch.randn(9, factors))\n",
    "        self.B = Parameter(torch.randn(factors, 12))\n",
    "    \n",
    "    def forward(self):\n",
    "        output = self.A.matmul(self.B)\n",
    "        return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactorizeBiasA(nn.Module):\n",
    "    \n",
    "    def __init__(self, factors=2):\n",
    "        super().__init__()\n",
    "        self.A = Parameter(torch.randn(9, factors))\n",
    "        self.B = Parameter(torch.randn(factors, 12))\n",
    "        self.bias_A = Parameter(torch.randn(9, 1))\n",
    "    \n",
    "    def forward(self):\n",
    "        output = self.A.matmul(self.B) + self.bias_A\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load hint_matrix_2.py\n",
    "model = Factorize(factors=2)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load hint 3... oh, no - actually, go to the previous notebooks :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "for i in range(10000):\n",
    "    \n",
    "    output = model()\n",
    "    loss = criterion(output, avg_temp_tensor)\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()        \n",
    "    optimizer.step()\n",
    "    \n",
    "show_loss(losses, logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame(model().detach().numpy(), index=cities, columns=months)\n",
    "sns.heatmap(df_pred, annot=True, fmt='.0f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df_pred - df, annot=True, fmt='.0f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randint_like(avg_temp_tensor, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cv(model, optimizer, epochs=10000):\n",
    "    losses = []\n",
    "    losses_val = []\n",
    "    mask = torch.randint_like(avg_temp_tensor, 0, 2)\n",
    "    for i in range(epochs):\n",
    "\n",
    "        output = model()\n",
    "        loss = (output - avg_temp_tensor).mul(mask).pow(2).sum() / mask.sum()\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        loss_val = (output - avg_temp_tensor).mul(1 - mask).pow(2).sum() / (1 - mask).sum()\n",
    "        losses_val.append(loss_val.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()        \n",
    "        optimizer.step()\n",
    "    return losses, losses_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Factorize(factors=2)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "losses, losses_val = train_cv(model, optimizer, epochs=10000)\n",
    "print(losses[-1], losses_val[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = [1, 2, 3, 4]\n",
    "res = []\n",
    "\n",
    "for d in dims:\n",
    "    model = Factorize(factors=d)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "    losses, losses_val = train_cv(model, optimizer, epochs=10000)\n",
    "    res.append({\n",
    "        'd': d,\n",
    "        'loss': losses[-1],\n",
    "        'losses_val': losses_val[-1]\n",
    "    })\n",
    "    \n",
    "pd.DataFrame(res).set_index('d').plot.bar(logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = [1, 2, 3, 4]\n",
    "res = []\n",
    "\n",
    "for d in dims:\n",
    "    model = FactorizeBiasA(factors=d)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "    losses, losses_val = train_cv(model, optimizer, epochs=10000)\n",
    "    res.append({\n",
    "        'd': d,\n",
    "        'loss': losses[-1],\n",
    "        'losses_val': losses_val[-1]\n",
    "    })\n",
    "    \n",
    "pd.DataFrame(res).set_index('d').plot.bar(logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-macos-m1-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:01:00) \n[Clang 13.0.1 ]"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "032715a8d60757555a2623145b534a689e8b5634c5398e8bbec1014c4a8ede12"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
